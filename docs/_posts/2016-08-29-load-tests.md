---
layout: page
title: "Load Tests"
category: ref
date: 2016-08-29 18:40:23
---

Load tests were conducted using mainly [loader.io](http://loader.io), that is
available as a Heroku plugin. Although other tools were used, their results
were all full of noise. I will comment a bit about the testing tools and why
they how they were used.

The tool that gave the most positive feedback was using `ab` under amazon
infrastructure. The reason why this was the most positive feedback is because
it don't count with network round-trip times, nor with interference caused by
running the benchmarks in a local virtual machine.

Another thing to note is that all tests with `ab` were done with **Free Dynos**
while some Loader.io tests were done using the pro dynos and some even with
multiple dynos in order to get better metrics.

### `JMeter`
JMeter results were intermittent, and I started to think that it was leaving open
connections in my linux machine, and this was giving false negatives. Mostly
because the local results from JMeter were very different from Apache `ab` test
tool. Also as all the development was being conducted in a virtual machine my
call was to drop JMeter.

### Apache `ab`

<span class='red'>NOTE:</span> `post_data.json` is commited to the repository under `scripts/load_testing/`.

The command user was `ab -c $N -n $N -p post_data.json
https://aqueous-citadel-94706.herokuapp.com/vehicles/log`, altering the N value
to represent concurrent connections. The result was according to the table:

|      | Running Local|            |               | Running AWS
| N    | Requests/sec | Time Taken | Time per Req. | Requests/sec | Time Taken | Time per Req. |
|------|--------------|------------|---------------|--------------|------------|---------------|
| 100  | 93.59        | 1.069s     | 10.685        | 118.99       | 0.840s     | 8.404         |
| 200  | 86.20        | 2.320s     | 11.601        | 175.00       | 1.143s     | 5.714         |
| 400  | 38.91        | 10.281s    | 25.703        | 163.89       | 2.441s     | 6.102         |
| 600  | 29.18        | 20.563s    | 34.272        | 202.94       | 2.957s     | 4.928         |
| 800  | 24.58        | 32.544s    | 40.680        | 95.77        | 8.353s     | 10.441        |
| 1000 | 24.29        | 41.174     | 41.174        | 141.33       | 7.076s     | 7.076         |

As we see in the charts running on amazon is much faster. This could be because
of Heroku runs on amazon, so all the connection were basically done locally.
This result is actually very good because it shows that with no network lag the
results are more than acceptable. A more detailed view of the 1000 result is
bellow (not the same run, just for narrowing the error margin.

    Server Software:        Cowboy
    Server Hostname:        aqueous-citadel-94706.herokuapp.com
    Server Port:            443
    SSL/TLS Protocol:       TLSv1.2,ECDHE-RSA-AES128-GCM-SHA256,2048,128
    
    Document Path:          /vehicles/log
    Document Length:        16 bytes
    
    Concurrency Level:      1000
    Time taken for tests:   5.232 seconds
    Complete requests:      1000
    Failed requests:        0
    Total transferred:      277000 bytes
    Total body sent:        353000
    HTML transferred:       16000 bytes
    Requests per second:    191.13 [#/sec] (mean)
    Time per request:       5231.927 [ms] (mean)
    Time per request:       5.232 [ms] (mean, across all concurrent requests)
    Transfer rate:          51.70 [Kbytes/sec] received
                            65.89 kb/s sent
                            117.59 kb/s total
    
    Connection Times (ms)
                  min  mean[+/-sd] median   max
    Connect:      629  885  49.6    862    1017
    Processing:   113 2206 1195.6   2191    4198
    Waiting:      112 2204 1196.9   2191    4197
    Total:        933 3091 1238.6   3055    5215
    
    Percentage of the requests served within a certain time (ms)
      50%   3055 - 66%   3780 - 75%   4166 - 80%   4386
      90%   4823 - 95%   5027 - 98%   5145 - 99%   5180
     100%   5215 (longest request)


### Loader.io

Another tool used to benchmark the API was Loader.io, mainly because it is
embedded in Heroku as an add-on. In another hand it doesn't have the
functionality of issuing a number of concurrent requests for a time interval
(such as the requirement: 1000 concurrent each 20 seconds) (and point to `ab`,
where this is easily scriptable). The results are in the images bellow.

Results get ugly very quickly and even launching more dynos the response times
don't go down very easily. The traffic generated by Loader.io seems to come
from Virginia-USA, they shouldn't be so bad when compared with the `ab` test.

Also we can see a lot of interference. It looks like network interference, but
there is no way to be sure, a more deep study should be done in order to
evaluate this.

To summarize what you will see in these images:

<span class="red">NOTE:</span> 3d is 3 heroku dynos; 6d is 6 heroku dynos.

**N**                  | 100  | 200   | 400    | 600    | 600-3d | 800    | 800-3d | 1000   | 1000-6d
**Avg. Response Time** | 18ms | 304ms | 5704ms | 7532ms | 8855ms | 5706ms | 3138ms | 17123ms| 3873ms


#### Result for 100
<img src="/backend-code-challenge/img/loader_io_100_per_sec.png" width="80%"/>

#### Result for 200
<img src="/backend-code-challenge/img/loader_io_200_per_sec.png" width="80%"/>

#### Result for 400
<img src="/backend-code-challenge/img/loader_io_400_per_sec.png" width="80%"/>

#### Result for 600
<img src="/backend-code-challenge/img/loader_io_600_per_sec.png" width="80%"/>

#### Result for 600 with 3 dynos
<img src="/backend-code-challenge/img/loader_io_600_3_per_sec.png" width="80%"/>

#### Result for 800
<img src="/backend-code-challenge/img/loader_io_800_per_sec.png" width="80%"/>

#### Result for 800 with 3 dynos
<img src="/backend-code-challenge/img/loader_io_800_per_sec_with_3_dynos.png" width="80%"/>

#### Result for 1000
<img src="/backend-code-challenge/img/loader_io_1000_per_sec.png" width="80%"/>

#### Result for 1000 with 6 dynos

*I really hope they don't charge me for this!*

<img src="/backend-code-challenge/img/loader_io_1000_per_sec_with_6_dynos.png" width="80%"/>
